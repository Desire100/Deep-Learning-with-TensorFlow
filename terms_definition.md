Learning Rate: defines the step size during gradient deecent.

Batch Size: batches allow us to use stochastic gradient descent. Smaller and bigger correspond to less representative of data and longer training time respectively.
